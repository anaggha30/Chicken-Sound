# ğŸ” Chicken Sound Recognition & Classification System

[![Language](https://img.shields.io/badge/Language-Python-blue?logo=python)](https://www.python.org/)
[![Libraries](https://img.shields.io/badge/Libraries-Librosa%20%7C%20TensorFlow%20%7C%20Keras%20%7C%20NumPy-orange)]()
[![Environment](https://img.shields.io/badge/Environment-Jupyter%20Notebook-lightgrey?logo=jupyter)](https://jupyter.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

An **AI-powered sound analysis project** designed to recognize and classify **chicken vocalizations** such as feeding, distress, happiness, and nesting sounds.  
This project applies **audio feature extraction** and **machine learning** to help understand **behavioral and environmental patterns** in poultry farms.

---

## ğŸš€ Features

- ğŸ”Š **Audio Classification:** Identifies different chicken sounds (e.g., happy, eating, distress, hungry).  
- ğŸ§  **Machine Learning Model:** Uses a CNN/LSTM-based sound classification model.  
- ğŸ“Š **Audio Feature Extraction:** Extracts features like **MFCC**, **spectrogram**, and **chroma**.  
- ğŸ§ **Dataset Handling:** Prepares `.wav` sound files into train-test datasets.  
- ğŸ£ **Behavior Monitoring:** Provides insights into chicken welfare and activity through sound analysis.  
- ğŸ’¾ **Efficient Storage:** Supports multiple `.wav` files organized by categories.  

---

## ğŸ§° Tech Stack

### ğŸ§  Tools & Libraries
- **Programming Language:** Python  
- **Libraries:** Librosa, NumPy, Pandas, TensorFlow/Keras, Matplotlib, Scikit-learn  
- **Environment:** Jupyter Notebook / Google Colab  

---

## ğŸ—ï¸ Project Architecture

```text
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚     Audio Dataset (.wav)   â”‚
 â”‚  (Happy, Eating, Hungry...)â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Audio Feature Extraction â”‚
 â”‚  (MFCC, Spectrogram, etc.)â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Model Training (CNN/LSTM)â”‚
 â”‚  Classification + Validationâ”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚     Sound Prediction App   â”‚
 â”‚  Identify chicken behavior â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/anaggha30/Chicken-Sound.git
cd Chicken-Sound
```

### 2ï¸âƒ£ Install Required Libraries
```bash
pip install numpy pandas librosa tensorflow scikit-learn matplotlib
```

### 3ï¸âƒ£ Run the Jupyter Notebook
```bash
jupyter notebook Chicken_Sound_Analysis.ipynb
```

### 4ï¸âƒ£ Add Your Dataset
Place your `.wav` files inside folders (e.g. `happy/`, `eating/`, `hungry/`) under a directory named **dataset**:
```
dataset/
 â”œâ”€â”€ happy/
 â”œâ”€â”€ eating/
 â”œâ”€â”€ hungry/
 â”œâ”€â”€ unclassified/
 â””â”€â”€ unknown/
```

---

## ğŸ“Š Sample Outputs

| Visualization | Description |
|----------------|--------------|
| ![Spectrogram](assets/spectrogram.png) | Spectrogram of chicken call frequency |
| ![Model Accuracy](assets/training_accuracy.png) | Model training accuracy and loss curves |
| ![Confusion Matrix](assets/confusion_matrix.png) | Model performance across sound categories |

---

## ğŸ§  Model Summary
- **Architecture:** CNN (Conv1D) / LSTM hybrid network  
- **Input:** MFCC features extracted using Librosa  
- **Output:** Predicted chicken sound category (e.g., *Eating*, *Happy*, *Hungry*, *Unknown*)  
- **Accuracy:** Depends on dataset quality (~85â€“90% on sample data)  

---

## ğŸ Future Enhancements
- ğŸ™ï¸ Real-time chicken sound detection using microphone input.  
- ğŸ“± Deploy model on a web or mobile app interface.  
- ğŸ“¡ Integrate IoT sensors for farm health monitoring.  
- ğŸ”Š Expand dataset with more diverse chicken sound categories.  

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€” youâ€™re free to use and modify it with attribution.

---

â­ **If you found this project helpful, donâ€™t forget to give it a star!**  
ğŸ‘‰ [GitHub Repository](https://github.com/anaggha30/Chicken-Sound)
